{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction of Various Tribuo Models from Tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%jars ../tribuo/Classification/Experiments/target/tribuo-classification-experiments-4.2.0-SNAPSHOT-jar-with-dependencies.jar\n",
    "%jars ../tribuo/Json/target/tribuo-json-4.2.0-SNAPSHOT-jar-with-dependencies.jar\n",
    "%jars ../tribuo/Regression/SGD/target/tribuo-regression-sgd-4.2.0-SNAPSHOT-jar-with-dependencies.jar\n",
    "%jars ../tribuo/Regression/XGBoost/target/tribuo-regression-xgboost-4.2.0-SNAPSHOT-jar-with-dependencies.jar\n",
    "%jars ../tribuo/Regression/RegressionTree/target/tribuo-regression-tree-4.2.0-SNAPSHOT-jar-with-dependencies.jar\n",
    "%jars ../tribuo/Clustering/KMeans/target/tribuo-clustering-kmeans-4.2.0-SNAPSHOT-jar-with-dependencies.jar\n",
    "%jars ../tribuo/AnomalyDetection/LibSVM/target/tribuo-anomaly-libsvm-4.2.0-SNAPSHOT-jar-with-dependencies.jar\n",
    "%jars ../tribuo/Interop/ONNX/target/tribuo-onnx-4.2.0-SNAPSHOT-jar-with-dependencies.jar\n",
    "\n",
    "%jars ../tribuo/Reproducibility/target/tribuo-reproducibility-4.2.0-SNAPSHOT-jar-with-dependencies.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.nio.file.Path;\n",
    "import java.nio.file.Paths;\n",
    "import java.nio.file.Files;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.tribuo.*;\n",
    "import org.tribuo.evaluation.TrainTestSplitter;\n",
    "import org.tribuo.data.csv.CSVLoader;\n",
    "import org.tribuo.datasource.ListDataSource;\n",
    "import org.tribuo.evaluation.TrainTestSplitter;\n",
    "import org.tribuo.classification.*;\n",
    "import org.tribuo.classification.evaluation.*;\n",
    "import org.tribuo.classification.sgd.linear.LogisticRegressionTrainer;\n",
    "import org.tribuo.classification.sgd.linear.LinearSGDModel;\n",
    "import org.tribuo.math.optimisers.*;\n",
    "import org.tribuo.regression.*;\n",
    "import org.tribuo.regression.evaluation.*;\n",
    "import org.tribuo.regression.sgd.RegressionObjective;\n",
    "import org.tribuo.regression.sgd.linear.LinearSGDTrainer;\n",
    "import org.tribuo.regression.sgd.objectives.SquaredLoss;\n",
    "import org.tribuo.regression.rtree.CARTRegressionTrainer;\n",
    "import org.tribuo.regression.rtree.impurity.MeanSquaredError;\n",
    "import org.tribuo.regression.xgboost.XGBoostRegressionTrainer;\n",
    "import org.tribuo.util.Util;\n",
    "\n",
    "import org.tribuo.provenance.DatasetProvenance;\n",
    "\n",
    "import org.tribuo.reproducibility.ReproUtil;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.fasterxml.jackson.databind.*;\n",
    "import com.oracle.labs.mlrg.olcut.provenance.ProvenanceUtil;\n",
    "import com.oracle.labs.mlrg.olcut.config.json.*;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileWriter fw = new FileWriter(\"./results/results.csv\");\n",
    "fw.append(\"Model, EqualEval, Diff, Dataset Name, Datasource, Note\\n\");\n",
    "fw.flush();\n",
    "fw.close();\n",
    "\n",
    "public String escapeSpecialCharacters(String data) {\n",
    "    String escapedData = data.replaceAll(\"\\\\R\", \" \");\n",
    "    if (data.contains(\",\") || data.contains(\"\\\"\") || data.contains(\"'\")) {\n",
    "        data = data.replace(\"\\\"\", \"\\\"\\\"\");\n",
    "        escapedData = \"\\\"\" + data + \"\\\"\";\n",
    "    }\n",
    "    return escapedData;\n",
    "}\n",
    "\n",
    "public void addToCSV(String model, String equal, String diff, String dataset, String datatype, String note) throws Exception{\n",
    "    FileWriter fw = new FileWriter(\"./results/results.csv\", true);\n",
    "    fw.append(escapeSpecialCharacters(model) + \",\"\n",
    "              + escapeSpecialCharacters(equal) + \",\" \n",
    "              + escapeSpecialCharacters(diff) + \",\" + dataset + \",\" + datatype + \",\" + note + \"\\n\");\n",
    "    fw.flush();\n",
    "    fw.close();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Irises Reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "var labelFactory = new LabelFactory();\n",
    "var csvLoader = new CSVLoader<>(labelFactory);\n",
    "\n",
    "var irisHeaders = new String[]{\"sepalLength\", \"sepalWidth\", \"petalLength\", \"petalWidth\", \"species\"};\n",
    "var irisesSource = csvLoader.loadDataSource(Paths.get(\"data/bezdekIris.data\"),\"species\",irisHeaders);\n",
    "var irisSplitter = new TrainTestSplitter<>(irisesSource,0.7,1L);\n",
    "\n",
    "var trainingDataset = new MutableDataset<>(irisSplitter.getTrain());\n",
    "var testingDataset = new MutableDataset<>(irisSplitter.getTest());\n",
    "\n",
    "Trainer<Label> trainer = new LogisticRegressionTrainer();\n",
    "\n",
    "Model<Label> irisModel = trainer.train(trainingDataset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "var repro = new ReproUtil(irisModel.getProvenance());\n",
    "Model<Label> newModel = repro.reproduceFromProvenance();\n",
    "\n",
    "var evaluator = new LabelEvaluator();\n",
    "var oldEvaluation = evaluator.evaluate(irisModel,testingDataset);\n",
    "var newEvaluation = evaluator.evaluate(newModel,testingDataset);\n",
    "oldEvaluation.toString().equals(newEvaluation.toString());\n",
    "addToCSV(irisModel.getProvenance().getClassName(), \n",
    "         String.valueOf(oldEvaluation.asMap().equals(newEvaluation.asMap())), \n",
    "         ReproUtil.diffProvenance(irisModel.getProvenance(), newModel.getProvenance()),\"Irises\", \"CSV*\", \"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Diff of a Reproduced Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dataset\" : {\n",
      "    \"datasource\" : {\n",
      "      \"source\" : {\n",
      "        \"datasource-creation-time\" : {\n",
      "          \"original\" : \"2021-10-14T20:35:58.855214828Z\",\n",
      "          \"reproduced\" : \"2021-10-14T20:35:59.140149069Z\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"trained-at\" : {\n",
      "    \"original\" : \"2021-10-14T20:35:59.010602778Z\",\n",
      "    \"reproduced\" : \"2021-10-14T20:35:59.154447735Z\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "System.out.println(ReproUtil.diffProvenance(irisModel.getProvenance(), newModel.getProvenance()) + '\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Wine Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-dimensional Regression Evaluation\n",
      "RMSE = {DIM-0=0.9674499961834514}\n",
      "Mean Absolute Error = {DIM-0=0.7206185708313483}\n",
      "R^2 = {DIM-0=-0.43925534551981915}\n",
      "explained variance = {DIM-0=-0.4073797682443554}\n",
      "Multi-dimensional Regression Evaluation\n",
      "RMSE = {DIM-0=0.7379938883670438}\n",
      "Mean Absolute Error = {DIM-0=0.5857086712272666}\n",
      "R^2 = {DIM-0=0.16249708522840767}\n",
      "explained variance = {DIM-0=0.1794985379830768}\n",
      "Multi-dimensional Regression Evaluation\n",
      "RMSE = {DIM-0=0.6587224004544178}\n",
      "Mean Absolute Error = {DIM-0=0.494394923264111}\n",
      "R^2 = {DIM-0=0.3327544882017498}\n",
      "explained variance = {DIM-0=0.33705711778611347}\n"
     ]
    }
   ],
   "source": [
    "public Model<Regressor> reproduceRegressor(Dataset<Regressor> trainData, Dataset<Regressor> testData, Trainer<Regressor> trainer, String note) throws Exception{\n",
    "    Model<Regressor> model = trainer.train(trainData);\n",
    "    \n",
    "    var repro = new ReproUtil(model.getProvenance());\n",
    "    Model<Regressor> newModel = repro.reproduceFromProvenance(); \n",
    "    \n",
    "    RegressionEvaluator eval = new RegressionEvaluator();\n",
    "    var oldEvaluation = eval.evaluate(model,testData);\n",
    "    var newEvaluation = eval.evaluate(newModel,testData);\n",
    "    System.out.println(oldEvaluation.toString());\n",
    "    \n",
    "    addToCSV(model.getProvenance().getClassName(),\n",
    "            String.valueOf(oldEvaluation.asMap().equals(newEvaluation.asMap())),\n",
    "            ReproUtil.diffProvenance(model.getProvenance(), newModel.getProvenance()), \"Wine Quality\", \"CSV*\", note);\n",
    "    return newModel;\n",
    "}\n",
    "\n",
    "var regressionFactory = new RegressionFactory();\n",
    "var csvLoader = new CSVLoader<>(';',regressionFactory);\n",
    "\n",
    "var wineSource = csvLoader.loadDataSource(Paths.get(\"data/winequality-red.csv\"),\"quality\");\n",
    "var splitter = new TrainTestSplitter<>(wineSource, 0.7f, 0L);\n",
    "Dataset<Regressor> trainData = new MutableDataset<>(splitter.getTrain());\n",
    "Dataset<Regressor> testData = new MutableDataset<>(splitter.getTest());\n",
    "\n",
    "var lrsgd = new LinearSGDTrainer(\n",
    "    new SquaredLoss(), // loss function\n",
    "    SGD.getLinearDecaySGD(0.01), // gradient descent algorithm\n",
    "    10,                // number of training epochs\n",
    "    trainData.size()/4,// logging interval\n",
    "    1,                 // minibatch size\n",
    "    1L                 // RNG seed\n",
    ");\n",
    "var lrada = new LinearSGDTrainer(\n",
    "    new SquaredLoss(),\n",
    "    new AdaGrad(0.01),\n",
    "    10,\n",
    "    trainData.size()/4,\n",
    "    1,\n",
    "    1L \n",
    ");\n",
    "var cart = new CARTRegressionTrainer(6);\n",
    "var xgb = new XGBoostRegressionTrainer(50);\n",
    "\n",
    "Model<Regressor> lrsgdModel = reproduceRegressor(trainData, testData, lrsgd, \"LinearDecaySGD\");\n",
    "Model<Regressor> lradaModel = reproduceRegressor(trainData, testData, lrada, \"AdaGrad\");\n",
    "Model<Regressor> cartModel = reproduceRegressor(trainData, testData, cart, \"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Diff with one Property Different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dataset\" : {\n",
      "    \"datasource\" : {\n",
      "      \"source\" : {\n",
      "        \"datasource-creation-time\" : {\n",
      "          \"original\" : \"2021-10-14T20:36:00.183591Z\",\n",
      "          \"reproduced\" : \"2021-10-14T20:35:59.903406845Z\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"trained-at\" : {\n",
      "    \"original\" : \"2021-10-14T20:36:00.240701209Z\",\n",
      "    \"reproduced\" : \"2021-10-14T20:36:00.589257176Z\"\n",
      "  },\n",
      "  \"trainer\" : {\n",
      "    \"epochs\" : {\n",
      "      \"original\" : \"10\",\n",
      "      \"reproduced\" : \"15\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "var lrsgd_epoch15 = new LinearSGDTrainer(\n",
    "    new SquaredLoss(), // loss function\n",
    "    SGD.getLinearDecaySGD(0.01), // gradient descent algorithm\n",
    "    15,                // number of training epochs\n",
    "    trainData.size()/4,// logging interval\n",
    "    1,                 // minibatch size\n",
    "    1L                 // RNG seed\n",
    ");\n",
    "Model<Regressor> model_epoch15 = lrsgd_epoch15.train(trainData);\n",
    "\n",
    "System.out.println(ReproUtil.diffProvenance(lrsgdModel.getProvenance(), model_epoch15.getProvenance()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Diff with Same Trainer but Different Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dataset\" : {\n",
      "    \"datasource\" : {\n",
      "      \"source\" : {\n",
      "        \"datasource-creation-time\" : {\n",
      "          \"original\" : \"2021-10-14T20:36:00.183591Z\",\n",
      "          \"reproduced\" : \"2021-10-14T20:36:00.296237765Z\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"trained-at\" : {\n",
      "    \"original\" : \"2021-10-14T20:36:00.240701209Z\",\n",
      "    \"reproduced\" : \"2021-10-14T20:36:00.330219018Z\"\n",
      "  },\n",
      "  \"trainer\" : {\n",
      "    \"optimiser\" : {\n",
      "      \"class-name\" : {\n",
      "        \"original\" : \"org.tribuo.math.optimisers.LinearDecaySGD\",\n",
      "        \"reproduced\" : \"org.tribuo.math.optimisers.AdaGrad\"\n",
      "      },\n",
      "      \"rho\" : {\n",
      "        \"original\" : \"0.0\"\n",
      "      },\n",
      "      \"useMomentum\" : {\n",
      "        \"original\" : \"NONE\"\n",
      "      },\n",
      "      \"epsilon\" : {\n",
      "        \"reproduced\" : \"1.0E-6\"\n",
      "      },\n",
      "      \"initialValue\" : {\n",
      "        \"reproduced\" : \"0.0\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "System.out.println(ReproUtil.diffProvenance(lrsgdModel.getProvenance(), lradaModel.getProvenance()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diff of Classification LinearSGDModel to Regression LinearSGDModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"class-name\" : {\n",
      "    \"original\" : \"org.tribuo.regression.sgd.linear.LinearSGDModel\",\n",
      "    \"reproduced\" : \"org.tribuo.classification.sgd.linear.LinearSGDModel\"\n",
      "  },\n",
      "  \"dataset\" : {\n",
      "    \"datasource\" : {\n",
      "      \"seed\" : {\n",
      "        \"original\" : \"0\",\n",
      "        \"reproduced\" : \"1\"\n",
      "      },\n",
      "      \"size\" : {\n",
      "        \"original\" : \"1599\",\n",
      "        \"reproduced\" : \"150\"\n",
      "      },\n",
      "      \"source\" : {\n",
      "        \"dataPath\" : {\n",
      "          \"original\" : \"/home/jupyter/eval/data/winequality-red.csv\",\n",
      "          \"reproduced\" : \"/home/jupyter/eval/data/bezdekIris.data\"\n",
      "        },\n",
      "        \"datasource-creation-time\" : {\n",
      "          \"original\" : \"2021-10-14T20:36:00.183591Z\",\n",
      "          \"reproduced\" : \"2021-10-14T20:35:58.855214828Z\"\n",
      "        },\n",
      "        \"file-modified-time\" : {\n",
      "          \"original\" : \"2009-10-16T21:36:50Z\",\n",
      "          \"reproduced\" : \"1999-12-14T20:12:39Z\"\n",
      "        },\n",
      "        \"resource-hash\" : {\n",
      "          \"original\" : \"4A402CF041B025D4566D954C3B9BA8635A3A8A01E039005D97D6A710278CF05E\",\n",
      "          \"reproduced\" : \"0FED2A99DB77EC533A62DC66894D3EC6DF3B58B6A8F3CF4A6B47E4086B7F97DC\"\n",
      "        },\n",
      "        \"separator\" : {\n",
      "          \"original\" : \";\",\n",
      "          \"reproduced\" : \",\"\n",
      "        }\n",
      "      },\n",
      "      \"train-proportion\" : {\n",
      "        \"original\" : \"0.699999988079071\",\n",
      "        \"reproduced\" : \"0.7\"\n",
      "      }\n",
      "    },\n",
      "    \"num-examples\" : {\n",
      "      \"original\" : \"1119\",\n",
      "      \"reproduced\" : \"105\"\n",
      "    },\n",
      "    \"num-features\" : {\n",
      "      \"original\" : \"11\",\n",
      "      \"reproduced\" : \"4\"\n",
      "    },\n",
      "    \"num-outputs\" : {\n",
      "      \"original\" : \"1\",\n",
      "      \"reproduced\" : \"3\"\n",
      "    }\n",
      "  },\n",
      "  \"trained-at\" : {\n",
      "    \"original\" : \"2021-10-14T20:36:00.240701209Z\",\n",
      "    \"reproduced\" : \"2021-10-14T20:35:59.010602778Z\"\n",
      "  },\n",
      "  \"trainer\" : {\n",
      "    \"class-name\" : {\n",
      "      \"original\" : \"org.tribuo.regression.sgd.linear.LinearSGDTrainer\",\n",
      "      \"reproduced\" : \"org.tribuo.classification.sgd.linear.LogisticRegressionTrainer\"\n",
      "    },\n",
      "    \"epochs\" : {\n",
      "      \"original\" : \"10\",\n",
      "      \"reproduced\" : \"5\"\n",
      "    },\n",
      "    \"loggingInterval\" : {\n",
      "      \"original\" : \"279\",\n",
      "      \"reproduced\" : \"1000\"\n",
      "    },\n",
      "    \"objective\" : {\n",
      "      \"class-name\" : {\n",
      "        \"original\" : \"org.tribuo.regression.sgd.objectives.SquaredLoss\",\n",
      "        \"reproduced\" : \"org.tribuo.classification.sgd.objectives.LogMulticlass\"\n",
      "      },\n",
      "      \"host-short-name\" : {\n",
      "        \"original\" : \"RegressionObjective\",\n",
      "        \"reproduced\" : \"LabelObjective\"\n",
      "      }\n",
      "    },\n",
      "    \"optimiser\" : {\n",
      "      \"class-name\" : {\n",
      "        \"original\" : \"org.tribuo.math.optimisers.LinearDecaySGD\",\n",
      "        \"reproduced\" : \"org.tribuo.math.optimisers.AdaGrad\"\n",
      "      },\n",
      "      \"initialLearningRate\" : {\n",
      "        \"original\" : \"0.01\",\n",
      "        \"reproduced\" : \"1.0\"\n",
      "      },\n",
      "      \"rho\" : {\n",
      "        \"original\" : \"0.0\"\n",
      "      },\n",
      "      \"useMomentum\" : {\n",
      "        \"original\" : \"NONE\"\n",
      "      },\n",
      "      \"epsilon\" : {\n",
      "        \"reproduced\" : \"0.1\"\n",
      "      },\n",
      "      \"initialValue\" : {\n",
      "        \"reproduced\" : \"0.0\"\n",
      "      }\n",
      "    },\n",
      "    \"seed\" : {\n",
      "      \"original\" : \"1\",\n",
      "      \"reproduced\" : \"12345\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "System.out.println(ReproUtil.diffProvenance(lrsgdModel.getProvenance(), irisModel.getProvenance()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.tribuo.transform.*;\n",
    "import org.tribuo.transform.transformations.LinearScalingTransformation;\n",
    "import org.tribuo.classification.*;\n",
    "import org.tribuo.classification.evaluation.*;\n",
    "import com.oracle.labs.mlrg.olcut.config.Configurable;\n",
    "import com.oracle.labs.mlrg.olcut.config.ConfigurationManager;\n",
    "import com.oracle.labs.mlrg.olcut.config.DescribeConfigurable;\n",
    "import com.oracle.labs.mlrg.olcut.provenance.*;\n",
    "import com.oracle.labs.mlrg.olcut.provenance.primitives.*;\n",
    "import com.oracle.labs.mlrg.olcut.config.json.JsonConfigFactory;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Trainer directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "var configPath = Paths.get(\"configs\",\"mnist-config.xml\");\n",
    "var cm = new ConfigurationManager(configPath.toString());\n",
    "var logistic = (Trainer<Label>) cm.lookup(\"logistic\");\n",
    "\n",
    "DataSource<Label> mnistTrain = (DataSource<Label>) cm.lookup(\"mnist-train\");\n",
    "DataSource<Label> mnistTest = (DataSource<Label>) cm.lookup(\"mnist-test\");\n",
    "\n",
    "var trainData = new MutableDataset<>(mnistTrain);\n",
    "var testData = new MutableDataset<>(mnistTest);\n",
    "var transformations = new TransformationMap(List.of(new LinearScalingTransformation(0,1)));\n",
    "var transformed = new TransformTrainer(logistic,transformations);\n",
    "var transformedModel = transformed.train(trainData);\n",
    "\n",
    "\n",
    "var repro = new ReproUtil(transformedModel.getProvenance());\n",
    "var newModel = repro.reproduceFromProvenance();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "var eval = new LabelEvaluator();\n",
    "var oldEvaluation = eval.evaluate((Model<Label>)transformedModel, mnistTest);\n",
    "var newEvaluation = eval.evaluate((Model<Label>)newModel, mnistTest);\n",
    "\n",
    "addToCSV(newModel.getProvenance().getClassName(),\n",
    "            String.valueOf(oldEvaluation.asMap().equals(newEvaluation.asMap())),\n",
    "            ReproUtil.diffProvenance(transformedModel.getProvenance(), newModel.getProvenance()),\"MNIST\", \"IDX\", \"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Trainer with TrainTestSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "var configPath = Paths.get(\"configs\",\"mnist-config.xml\");\n",
    "var cm = new ConfigurationManager(configPath.toString());\n",
    "var logistic = (Trainer<Label>) cm.lookup(\"logistic\");\n",
    "\n",
    "DataSource<Label> mnistTrain = (DataSource<Label>) cm.lookup(\"mnist-train\");\n",
    "TrainTestSplitter splitter = new TrainTestSplitter(mnistTrain);\n",
    "\n",
    "var trainData = new MutableDataset<>(splitter.getTrain());\n",
    "var testData = new MutableDataset<>(splitter.getTest());\n",
    "var transformations = new TransformationMap(List.of(new LinearScalingTransformation(0,1)));\n",
    "var transformed = new TransformTrainer(logistic,transformations);\n",
    "var transformedModel = transformed.train(trainData);\n",
    "\n",
    "\n",
    "var repro = new ReproUtil(transformedModel.getProvenance());\n",
    "var newModel = repro.reproduceFromProvenance();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "var eval = new LabelEvaluator();\n",
    "var oldEvaluation = eval.evaluate((Model<Label>)transformedModel, mnistTest);\n",
    "var newEvaluation = eval.evaluate((Model<Label>)newModel, mnistTest);\n",
    "\n",
    "addToCSV(newModel.getProvenance().getClassName(),\n",
    "            String.valueOf(oldEvaluation.asMap().equals(newEvaluation.asMap())),\n",
    "            ReproUtil.diffProvenance(transformedModel.getProvenance(), newModel.getProvenance()), \"MNIST\",\"IDX\", \"With TrainTestSplitter\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.tribuo.clustering.*;\n",
    "import org.tribuo.clustering.evaluation.*;\n",
    "import org.tribuo.clustering.example.GaussianClusterDataSource;\n",
    "import org.tribuo.clustering.kmeans.*;\n",
    "import org.tribuo.clustering.kmeans.KMeansTrainer.Distance;\n",
    "import org.tribuo.clustering.kmeans.KMeansTrainer.Initialisation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "var eval = new ClusteringEvaluator();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "var data = new MutableDataset<>(new GaussianClusterDataSource(500, 1L));\n",
    "var test = new MutableDataset<>(new GaussianClusterDataSource(500, 2L));\n",
    "\n",
    "var trainer = new KMeansTrainer(5, /* centroids */\n",
    "                                10, /* iterations */\n",
    "                                Distance.EUCLIDEAN, /* distance function */\n",
    "                                1, /* number of compute threads */\n",
    "                                1 /* RNG seed */\n",
    "                               );\n",
    "var kmeansModel = trainer.train(data);\n",
    "var kmRepro = new ReproUtil(kmeansModel);\n",
    "var newKmeans = kmRepro.reproduceFromProvenance();\n",
    "\n",
    "var oldEvaluation = eval.evaluate(kmeansModel, test);\n",
    "var newEvaluation = eval.evaluate((KMeansModel)newKmeans, test);\n",
    "\n",
    "addToCSV(kmeansModel.getProvenance().getClassName(),\n",
    "        String.valueOf(oldEvaluation.asMap().equals(newEvaluation.asMap())),\n",
    "        ReproUtil.diffProvenance(kmeansModel.getProvenance(), newKmeans.getProvenance()), \"Generated\", \"Generator\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans++ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "var plusplusTrainer = new KMeansTrainer(5,10,Distance.EUCLIDEAN,Initialisation.PLUSPLUS,1,1);\n",
    "var plusplusModel = plusplusTrainer.train(data);\n",
    "\n",
    "var plusplusRepro = new ReproUtil(plusplusModel);\n",
    "var newPlusPlus = plusplusRepro.reproduceFromProvenance();\n",
    "\n",
    "var oldEvaluation = eval.evaluate(plusplusModel, test);\n",
    "var newEvaluation = eval.evaluate((KMeansModel)newPlusPlus, test);\n",
    "\n",
    "addToCSV(plusplusModel.getProvenance().getClassName(),\n",
    "        String.valueOf(oldEvaluation.asMap().equals(newEvaluation.asMap())),\n",
    "        ReproUtil.diffProvenance(plusplusModel.getProvenance(), newPlusPlus.getProvenance()),\"Generated\",\"Generator\", \"KMeans++\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection with LibSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.tribuo.anomaly.*;\n",
    "import org.tribuo.anomaly.evaluation.*;\n",
    "import org.tribuo.anomaly.example.GaussianAnomalyDataSource;\n",
    "import org.tribuo.anomaly.libsvm.*;\n",
    "import org.tribuo.common.libsvm.*;\n",
    "\n",
    "var eval = new AnomalyEvaluator();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*\n",
      "optimization finished, #iter = 653\n",
      "obj = 289.5926348816893, rho = 3.144570476807895\n",
      "nSV = 296, nBSV = 114\n",
      "*\n",
      "optimization finished, #iter = 653\n",
      "obj = 289.5926348816893, rho = 3.144570476807895\n",
      "nSV = 296, nBSV = 114\n"
     ]
    }
   ],
   "source": [
    "var data = new MutableDataset<>(new GaussianAnomalyDataSource(2000,/* number of examples */\n",
    "                                                              0.0f,/*fraction anomalous */\n",
    "                                                              1L/* RNG seed */));\n",
    "var test = new MutableDataset<>(new GaussianAnomalyDataSource(2000,0.2f,2L));\n",
    "\n",
    "var params = new SVMParameters<>(new SVMAnomalyType(SVMAnomalyType.SVMMode.ONE_CLASS), KernelType.RBF);\n",
    "params.setGamma(1.0);\n",
    "params.setNu(0.1); \n",
    "var trainer = new LibSVMAnomalyTrainer(params);\n",
    "\n",
    "var anomModel = trainer.train(data);\n",
    "\n",
    "var anomRepro = new ReproUtil(anomModel);\n",
    "var newAnom = anomRepro.reproduceFromProvenance();\n",
    "\n",
    "var oldEvaluation = eval.evaluate(anomModel,test);\n",
    "var newEvaluation = eval.evaluate((LibSVMModel)newAnom,test);\n",
    "\n",
    "addToCSV(anomModel.getProvenance().getClassName(),\n",
    "        String.valueOf(oldEvaluation.asMap().equals(newEvaluation.asMap())),\n",
    "        ReproUtil.diffProvenance(anomModel.getProvenance(), newAnom.getProvenance()), \"Generated\",\"Generator\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Columnar Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.nio.charset.StandardCharsets;\n",
    "import java.util.Locale;\n",
    "import java.util.stream.*;\n",
    "\n",
    "import com.oracle.labs.mlrg.olcut.config.ConfigurationManager;\n",
    "import com.oracle.labs.mlrg.olcut.provenance.ProvenanceUtil;\n",
    "\n",
    "import org.tribuo.*;\n",
    "import org.tribuo.data.columnar.*;\n",
    "import org.tribuo.data.columnar.processors.field.*;\n",
    "import org.tribuo.data.columnar.processors.response.*;\n",
    "import org.tribuo.data.columnar.extractors.*;\n",
    "import org.tribuo.data.csv.CSVDataSource;\n",
    "import org.tribuo.data.text.impl.BasicPipeline;\n",
    "import org.tribuo.json.JsonDataSource;\n",
    "import org.tribuo.classification.*;\n",
    "import org.tribuo.classification.sgd.linear.LogisticRegressionTrainer;\n",
    "import org.tribuo.util.tokens.impl.BreakIteratorTokenizer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "var csvPath = Paths.get(\"..\", \"tribuo\", \"tutorials\", \"columnar-data\",\"columnar-example.csv\");\n",
    "var csvLines = Files.readAllLines(csvPath, StandardCharsets.UTF_8);\n",
    "\n",
    "BasicPipeline textPipeline = new BasicPipeline(new BreakIteratorTokenizer(Locale.US),2);\n",
    "HashMap<String, FieldProcessor> fieldProcessors = new HashMap<String, FieldProcessor>();\n",
    "\n",
    "fieldProcessors.put(\"height\",new DoubleFieldProcessor(\"height\"));\n",
    "fieldProcessors.put(\"description\",new TextFieldProcessor(\"description\",textPipeline));\n",
    "fieldProcessors.put(\"transport\",new IdentityProcessor(\"transport\"));\n",
    "\n",
    "HashMap<String,FieldProcessor> regexMappingProcessors = new HashMap<String,FieldProcessor>();\n",
    "regexMappingProcessors.put(\"extra.*\", new DoubleFieldProcessor(\"extra.*\"));\n",
    "\n",
    "FieldResponseProcessor responseProcessor = new FieldResponseProcessor(\"disposition\",\"UNK\",new LabelFactory());\n",
    "\n",
    "ArrayList<FieldExtractor<?>> metadataExtractors = new ArrayList<FieldExtractor<?>>();\n",
    "metadataExtractors.add(new IntExtractor(\"id\"));\n",
    "metadataExtractors.add(new DateExtractor(\"timestamp\",\"timestamp\",\"dd/MM/yyyy HH:mm\"));\n",
    "\n",
    "FloatExtractor weightExtractor = new FloatExtractor(\"example-weight\");\n",
    "\n",
    "RowProcessor<Label> rowProcessor = new RowProcessor<Label>(metadataExtractors,weightExtractor,responseProcessor,fieldProcessors,regexMappingProcessors, Collections.emptySet());\n",
    "\n",
    "var jsonPath = Paths.get(\"..\", \"tribuo\", \"tutorials\", \"columnar-data\",\"columnar-example.json\");\n",
    "var jsonLines = Files.readAllLines(jsonPath, StandardCharsets.UTF_8);\n",
    "\n",
    "var jsonSource = new JsonDataSource<>(jsonPath,rowProcessor,true);\n",
    "CSVDataSource csvSource = new CSVDataSource<Label>(csvPath,rowProcessor,true);\n",
    "\n",
    "var csvSplitter = new TrainTestSplitter(csvSource);\n",
    "var jsonSplitter = new TrainTestSplitter(jsonSource);\n",
    "\n",
    "\n",
    "MutableDataset<Label> datasetFromJson = new MutableDataset<Label>(jsonSplitter.getTrain());\n",
    "MutableDataset<Label> datasetFromCSV = new MutableDataset<Label>(csvSplitter.getTrain());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "var csvModel = new LogisticRegressionTrainer().train(datasetFromCSV);\n",
    "var jsonModel = new LogisticRegressionTrainer().train(datasetFromJson);\n",
    "\n",
    "var csvRepro = new ReproUtil(csvModel);\n",
    "var jsonRepro = new ReproUtil(jsonModel);\n",
    "\n",
    "var newCSV = csvRepro.reproduceFromProvenance();\n",
    "var newJson = jsonRepro.reproduceFromProvenance();\n",
    "\n",
    "var evaluator = new LabelEvaluator();\n",
    "\n",
    "var csvEval = evaluator.evaluate(csvModel, new MutableDataset(csvSplitter.getTest()));\n",
    "var jsonEval = evaluator.evaluate(jsonModel, new MutableDataset(jsonSplitter.getTest()));\n",
    "\n",
    "var newCsvEval = evaluator.evaluate((LinearSGDModel) newCSV, new MutableDataset(csvSplitter.getTest()));\n",
    "var newJsonEval = evaluator.evaluate((LinearSGDModel) newJson, new MutableDataset(jsonSplitter.getTest()));\n",
    "\n",
    "addToCSV(csvModel.getProvenance().getClassName(),\n",
    "        String.valueOf(csvEval.asMap().equals(newCsvEval.asMap())),\n",
    "        ReproUtil.diffProvenance(csvModel.getProvenance(), newCSV.getProvenance()), \"Generated\", \"CSV\", \"CSV Columnar with TrainTest\");\n",
    "addToCSV(jsonModel.getProvenance().getClassName(),\n",
    "        String.valueOf(jsonEval.asMap().equals(newJsonEval.asMap())),\n",
    "        ReproUtil.diffProvenance(jsonModel.getProvenance(), newJson.getProvenance()), \"Generated\", \"JSON\", \"JSON Columnar with TrainTest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.Collections;\n",
    "import java.nio.file.Paths;\n",
    "import com.oracle.labs.mlrg.olcut.provenance.ProvenanceUtil;\n",
    "import com.oracle.labs.mlrg.olcut.util.Pair;\n",
    "import org.tribuo.*;\n",
    "import org.tribuo.data.text.*;\n",
    "import org.tribuo.data.text.impl.*;\n",
    "import org.tribuo.dataset.MinimumCardinalityDataset;\n",
    "import org.tribuo.classification.*;\n",
    "import org.tribuo.classification.evaluation.*;\n",
    "import org.tribuo.classification.sgd.linear.LinearSGDTrainer;\n",
    "import org.tribuo.classification.sgd.objectives.LogMulticlass;\n",
    "import org.tribuo.interop.onnx.extractors.BERTFeatureExtractor;\n",
    "import org.tribuo.math.optimisers.AdaGrad;\n",
    "import org.tribuo.transform.*;\n",
    "import org.tribuo.transform.transformations.IDFTransformation;\n",
    "import org.tribuo.util.tokens.universal.UniversalTokenizer;\n",
    "import org.tribuo.util.Util;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bow training data size = 11314, number of features = 122024, number of classes = 20\n",
      "bow testing data size = 7532, number of features = 122024, number of classes = 20\n"
     ]
    }
   ],
   "source": [
    "var labelFactory = new LabelFactory();\n",
    "var labelEvaluator = new LabelEvaluator();\n",
    "var trainPath = Paths.get(\"data\",\"20news\",\"20news-bydate-train\");\n",
    "var testPath = Paths.get(\"data\",\"20news\",\"20news-bydate-test\");\n",
    "var tokenizer = new UniversalTokenizer();\n",
    "var bowPipeline = new BasicPipeline(tokenizer,1);\n",
    "var bowExtractor = new TextFeatureExtractorImpl<Label>(bowPipeline);\n",
    "\n",
    "var newsProc = new NewsPreprocessor();\n",
    "var lowercase = new CasingPreprocessor(CasingPreprocessor.CasingOperation.LOWERCASE);\n",
    "\n",
    "public Pair<Dataset<Label>,Dataset<Label>> mkDatasets(String name, TextFeatureExtractor<Label> extractor) {\n",
    "    var trainSource = new DirectoryFileSource<>(trainPath,labelFactory,extractor,newsProc,lowercase);\n",
    "    var testSource = new DirectoryFileSource<>(testPath,labelFactory,extractor,newsProc,lowercase);\n",
    "    var trainDS = new MutableDataset<>(trainSource);\n",
    "    var testDS = new ImmutableDataset<>(testSource,trainDS.getFeatureIDMap(),trainDS.getOutputIDInfo(),true);\n",
    "    System.out.println(String.format(name + \" training data size = %d, number of features = %d, number of classes = %d\",trainDS.size(),trainDS.getFeatureMap().size(),trainDS.getOutputInfo().size()));\n",
    "    System.out.println(String.format(name + \" testing data size = %d, number of features = %d, number of classes = %d\",testDS.size(),testDS.getFeatureMap().size(),testDS.getOutputInfo().size()));\n",
    "    return new Pair<>(trainDS,testDS);\n",
    "}\n",
    "\n",
    "var bowPair = mkDatasets(\"bow\",bowExtractor);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "var lrTrainer = new LinearSGDTrainer(new LogMulticlass(),new AdaGrad(0.1,0.001),5,42);\n",
    "var bowModel = lrTrainer.train(bowPair.getA());\n",
    "\n",
    "var bowRepro = new ReproUtil(bowModel);\n",
    "var newBow = bowRepro.reproduceFromProvenance();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "var oldEvaluation = labelEvaluator.evaluate(bowModel,bowPair.getB());\n",
    "var newEvaluation = labelEvaluator.evaluate((LinearSGDModel)newBow,bowPair.getB());\n",
    "\n",
    "addToCSV(bowModel.getProvenance().getClassName(),\n",
    "        String.valueOf(oldEvaluation.asMap().equals(newEvaluation.asMap())),\n",
    "        ReproUtil.diffProvenance(bowModel.getProvenance(), newBow.getProvenance()), \"20 News\", \"Directory of files\", \"BoW Simple Logistic\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram training data size = 11314, number of features = 122024, number of classes = 20\n",
      "unigram testing data size = 7532, number of features = 122024, number of classes = 20\n"
     ]
    }
   ],
   "source": [
    "var unigramPipeline = new TokenPipeline(tokenizer, 1, true);\n",
    "var unigramExtractor = new TextFeatureExtractorImpl<Label>(unigramPipeline);\n",
    "var unigramPair = mkDatasets(\"unigram\",unigramExtractor);\n",
    "\n",
    "var model = lrTrainer.train(unigramPair.getA());\n",
    "var repro = new ReproUtil(model);\n",
    "var newModel = repro.reproduceFromProvenance();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "var oldEvaluation = labelEvaluator.evaluate(model,unigramPair.getB());\n",
    "var newEvaluation = labelEvaluator.evaluate((LinearSGDModel)newModel,unigramPair.getB());\n",
    "\n",
    "addToCSV(model.getProvenance().getClassName(),\n",
    "        String.valueOf(oldEvaluation.asMap().equals(newEvaluation.asMap())),\n",
    "        ReproUtil.diffProvenance(model.getProvenance(), newModel.getProvenance()), \"20 News\", \"Directory of files\", \"Unigram Logistic\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram training data size = 11314, number of features = 1143035, number of classes = 20\n",
      "bigram testing data size = 7532, number of features = 1143035, number of classes = 20\n"
     ]
    }
   ],
   "source": [
    "var bigramPipeline = new TokenPipeline(tokenizer, 2, true);\n",
    "var bigramExtractor = new TextFeatureExtractorImpl<Label>(bigramPipeline);\n",
    "var bigramPair = mkDatasets(\"bigram\",bigramExtractor);\n",
    "\n",
    "var model = lrTrainer.train(bigramPair.getA());\n",
    "var repro = new ReproUtil(model);\n",
    "var newModel = repro.reproduceFromProvenance(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "var oldEvaluation = labelEvaluator.evaluate(model,unigramPair.getB());\n",
    "var newEvaluation = labelEvaluator.evaluate((LinearSGDModel)newModel,unigramPair.getB());\n",
    "\n",
    "addToCSV(model.getProvenance().getClassName(),\n",
    "        String.valueOf(oldEvaluation.asMap().equals(newEvaluation.asMap())),\n",
    "        ReproUtil.diffProvenance(model.getProvenance(), newModel.getProvenance()),\"20 News\", \"Directory of files\", \"Bigram Logistic\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "16.0.2+7-67"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

